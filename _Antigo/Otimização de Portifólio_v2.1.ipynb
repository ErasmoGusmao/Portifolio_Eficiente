{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b56a44f3",
   "metadata": {},
   "source": [
    "# Otimização de Portfólio em BRL \n",
    "_Markowitz, Fronteira Eficiente, Monte Carlo e Sharpe vs CDI_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fa6110",
   "metadata": {},
   "source": [
    "#### BLOCO 1 - Definição dos ativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6342e976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Configurações ======\n",
    "DATA_INICIO = \"2020-01-01\"\n",
    "DATA_FIM = \"2026-01-01\"\n",
    "DIAS_UTEIS_ANO = 252  # referência (pregão)\n",
    "\n",
    "# (Flag) Mistura ações/ETFs x cripto no calendário\n",
    "# False: dias úteis (252) — simples; cripto no fim de semana é ignorado\n",
    "# True: diário (365) — inclui fim de semana; ações ficam \"flat\" no fim de semana\n",
    "USAR_CALENDARIO_DIARIO = True\n",
    "\n",
    "FATOR_ANUALIZACAO = 365 if USAR_CALENDARIO_DIARIO else 252\n",
    "\n",
    "# ====== Ativos (moeda-base: BRL) ======\n",
    "# Brasil (B3) - já em BRL\n",
    "ativos_br = {\n",
    "    \"PETR4\": \"PETR4.SA\",\n",
    "    \"ITUB4\": \"ITUB4.SA\",\n",
    "    \"VALE3\": \"VALE3.SA\",\n",
    "    \"BBAS3\": \"BBAS3.SA\",\n",
    "    \"QBTC11\": \"QBTC11.SA\",\n",
    "}\n",
    "\n",
    "# EUA - em USD (serão convertidos para BRL)\n",
    "ativos_us = {\n",
    "    \"GOOGL\": \"GOOGL\",\n",
    "    \"NVDA\": \"NVDA\",\n",
    "    \"NDAQ\": \"NDAQ\",\n",
    "    \"META\": \"META\",\n",
    "    \"AMZN\": \"AMZN\",\n",
    "    \"VOO\": \"VOO\",\n",
    "}\n",
    "\n",
    "# Cripto - em USD (serão convertidos para BRL)\n",
    "cripto_usd = {\n",
    "    \"BTC\": \"BTC-USD\",\n",
    "    \"SOL\": \"SOL-USD\",\n",
    "}\n",
    "\n",
    "# USDC = CAIXA (fora da otimização)\n",
    "# Se quiser usar na carteira final como % em caixa, defina aqui:\n",
    "PESO_CAIXA_USDC = 0.00  # ex.: 0.10 para 10% em caixa (USDC)\n",
    "RETORNO_CAIXA_ANUAL = 0.0  # opcional: defina um retorno anual pro caixa (ex.: CDI aproximado)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9da7cb",
   "metadata": {},
   "source": [
    "#### Bloco 2 - Bibliotecas Necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89a5d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from scipy.optimize import minimize\n",
    "# import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff660a1",
   "metadata": {},
   "source": [
    "#### Etapa 1: Download + conversão USD→BRL + retornos e cov (substitua o seu bloco “Baixar dados / Calcular retornos”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a157ecd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _baixar_preco_adjclose(tickers, start, end):\n",
    "    raw = yf.download(tickers, start=start, end=end, progress=False, auto_adjust=False)\n",
    "    if raw.empty:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Preferir Adj Close, mas fazer fallback para Close\n",
    "    if isinstance(raw.columns, pd.MultiIndex):\n",
    "        if \"Adj Close\" in raw.columns.get_level_values(0):\n",
    "            px = raw[\"Adj Close\"].copy()\n",
    "        elif \"Close\" in raw.columns.get_level_values(0):\n",
    "            px = raw[\"Close\"].copy()\n",
    "        else:\n",
    "            raise ValueError(\"Não encontrei colunas 'Adj Close' nem 'Close' no retorno do yfinance.\")\n",
    "    else:\n",
    "        # Caso raro: sem MultiIndex\n",
    "        px = raw.copy()\n",
    "\n",
    "    px = px.dropna(axis=1, how=\"all\")\n",
    "    return px\n",
    "\n",
    "\n",
    "def _baixar_usdbrl(start, end):\n",
    "    # Tenta os dois formatos mais comuns no Yahoo\n",
    "    for fx_ticker in [\"BRL=X\", \"USDBRL=X\"]:\n",
    "        fx = _baixar_preco_adjclose([fx_ticker], start, end)\n",
    "        if not fx.empty:\n",
    "            s = fx.iloc[:, 0].rename(\"USDBRL\").dropna()\n",
    "            return s\n",
    "    raise ValueError(\"Não consegui baixar o câmbio USD/BRL (tentei 'BRL=X' e 'USDBRL=X').\")\n",
    "\n",
    "\n",
    "# ====== Monta lista de tickers a baixar (USDC fora) ======\n",
    "tickers_br = list(ativos_br.values())\n",
    "tickers_us = list(ativos_us.values())\n",
    "tickers_crypto = list(cripto_usd.values())\n",
    "\n",
    "TICKERS = tickers_br + tickers_us + tickers_crypto\n",
    "\n",
    "# ====== Baixar preços ======\n",
    "precos_raw = _baixar_preco_adjclose(TICKERS, DATA_INICIO, DATA_FIM)\n",
    "if precos_raw.empty:\n",
    "    raise ValueError(\"Download retornou vazio. Verifique tickers, conexão e período.\")\n",
    "\n",
    "usdbrl_raw = _baixar_usdbrl(DATA_INICIO, DATA_FIM)\n",
    "\n",
    "# ====== Calendário: dias úteis (252) vs diário (365) ======\n",
    "if USAR_CALENDARIO_DIARIO:\n",
    "    # calendário diário: inclui fins de semana\n",
    "    idx = pd.date_range(start=precos_raw.index.min(), end=precos_raw.index.max(), freq=\"D\")\n",
    "\n",
    "    # Reindex e forward-fill: ações ficam constantes no fim de semana; cripto já tem dados diários\n",
    "    precos = precos_raw.reindex(idx).ffill()\n",
    "    usdbrl = usdbrl_raw.reindex(idx).ffill()\n",
    "\n",
    "else:\n",
    "    # dias úteis: usa apenas interseção das datas com USD/BRL (normalmente pregões)\n",
    "    df_tmp = precos_raw.join(usdbrl_raw, how=\"inner\")\n",
    "    if df_tmp.empty:\n",
    "        raise ValueError(\"Após alinhar com o câmbio (dias úteis), não restaram datas em comum.\")\n",
    "    # separa novamente\n",
    "    usdbrl = df_tmp[\"USDBRL\"]\n",
    "    precos = df_tmp.drop(columns=[\"USDBRL\"])\n",
    "\n",
    "# Junta para converter USD -> BRL\n",
    "df = precos.join(usdbrl.rename(\"USDBRL\"), how=\"inner\" if not USAR_CALENDARIO_DIARIO else \"left\").ffill()\n",
    "\n",
    "# ====== Converter colunas USD -> BRL ======\n",
    "usd_cols = [c for c in (tickers_us + tickers_crypto) if c in df.columns]\n",
    "for c in usd_cols:\n",
    "    df[c] = df[c] * df[\"USDBRL\"]\n",
    "\n",
    "# Remove coluna do câmbio do dataframe de preços\n",
    "dados_brl = df.drop(columns=[\"USDBRL\"])\n",
    "\n",
    "# ====== Renomear colunas para os nomes “lógicos” (PETR4, NVDA, BTC, etc.) ======\n",
    "ticker_to_nome = {v: k for k, v in ativos_br.items()}\n",
    "ticker_to_nome.update({v: k for k, v in ativos_us.items()})\n",
    "ticker_to_nome.update({v: k for k, v in cripto_usd.items()})\n",
    "\n",
    "dados_brl = dados_brl.rename(columns=ticker_to_nome)\n",
    "\n",
    "# Remove colunas eventualmente faltantes\n",
    "dados_brl = dados_brl.dropna(axis=1, how=\"all\")\n",
    "if dados_brl.shape[1] < 2:\n",
    "    raise ValueError(\"Poucos ativos com dados válidos após limpeza. Verifique tickers.\")\n",
    "\n",
    "# ====== Retornos ======\n",
    "retornos = dados_brl.pct_change().dropna()\n",
    "\n",
    "# ====== Estatísticas anualizadas (Markowitz) ======\n",
    "retornos_medios_anuais = retornos.mean() * FATOR_ANUALIZACAO\n",
    "matriz_covariancia = retornos.cov() * FATOR_ANUALIZACAO\n",
    "\n",
    "print(\"Calendário diário:\", USAR_CALENDARIO_DIARIO, \"| Fator anualização:\", FATOR_ANUALIZACAO)\n",
    "print(\"Ativos usados na otimização (tudo em BRL):\", list(retornos.columns))\n",
    "print(\"PESO_CAIXA_USDC (fora da otimização):\", PESO_CAIXA_USDC)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad7c009",
   "metadata": {},
   "source": [
    "#### Etapa 1.5: Taxa livre de risco (rf) via CDI (B3/CETIP) usando BCData/SGS (série 12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9199e725",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def baixar_cdi_diaria_b3_via_sgs(data_inicio: str, data_fim: str) -> pd.Series:\n",
    "    \"\"\"CDI (B3/CETIP) obtido via canal aberto BCData/SGS (série 12). Retorna em decimal/dia.\"\"\"\n",
    "    di = pd.to_datetime(data_inicio).strftime(\"%d/%m/%Y\")\n",
    "    df = pd.to_datetime(data_fim).strftime(\"%d/%m/%Y\")\n",
    "    url = (\n",
    "        \"https://api.bcb.gov.br/dados/serie/bcdata.sgs.12/dados\"\n",
    "        f\"?formato=json&dataInicial={di}&dataFinal={df}\"\n",
    "    )\n",
    "    cdi = pd.read_json(url)\n",
    "    if cdi.empty:\n",
    "        raise ValueError(\"CDI vazio. Verifique período e acesso à internet.\")\n",
    "    cdi[\"data\"] = pd.to_datetime(cdi[\"data\"], dayfirst=True)\n",
    "    cdi[\"valor\"] = pd.to_numeric(cdi[\"valor\"], errors=\"coerce\")\n",
    "    s = (cdi.set_index(\"data\")[\"valor\"] / 100.0).rename(\"CDI_d\")  # % a.d. -> decimal/dia\n",
    "    return s.dropna()\n",
    "\n",
    "def rf_anual_equivalente(cdi_diario: pd.Series, dias_ano_ref: int = 252) -> float:\n",
    "    \"\"\"rf anual equivalente composto a partir de CDI diária (decimal/dia).\"\"\"\n",
    "    return float(np.expm1(np.log1p(cdi_diario).mean() * dias_ano_ref))\n",
    "\n",
    "# --- rf anual equivalente (composto) ---\n",
    "# Observação: este bloco requer internet para consultar a API do BCB (SGS),\n",
    "# mas a taxa CDI é de mercado (B3/CETIP).\n",
    "# Se você estiver offline, defina RF_ANUAL manualmente (ex.: RF_ANUAL = 0.10 para 10% a.a.)\n",
    "\n",
    "try:\n",
    "    cdi_d = baixar_cdi_diaria_b3_via_sgs(DATA_INICIO, DATA_FIM)\n",
    "\n",
    "    # rf anual equivalente (usa referência de 252 pregões; não depende do calendário diário)\n",
    "    RF_ANUAL = rf_anual_equivalente(cdi_d, dias_ano_ref=252)\n",
    "\n",
    "except Exception as e:\n",
    "    RF_ANUAL = 0.0\n",
    "    print(\"⚠️ Não foi possível baixar CDI (usando RF_ANUAL=0.0). Erro:\", e)\n",
    "\n",
    "print(f\"RF_ANUAL (CDI B3/CETIP via SGS) usado no Sharpe: {RF_ANUAL*100:.2f}% a.a.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da237c29",
   "metadata": {},
   "source": [
    "> **Nota sobre ações/ETFs x cripto (calendário):**  \n",
    "> Seu notebook está anualizando por **252 dias úteis**, o que é coerente se você modela rebalanceamento apenas em pregão.  \n",
    "> Para cripto (BTC/SOL), isso **ignora fins de semana** e pode **subestimar** a volatilidade.  \n",
    ">  \n",
    "> **Alternativas recomendadas:**  \n",
    "> 1) **Modelo “dias úteis” (252):** mantém tudo em pregão (simples e consistente com bolsa).  \n",
    "> 2) **Modelo “diário” (365):** reindexa tudo para todos os dias; ações/ETFs ficam “flat” no fim de semana (retorno 0), e cripto mantém variação 7/7.  \n",
    ">  \n",
    "> Se quiser, eu adapto seu bloco de download para alternar entre os dois modelos com uma flag.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d265ef8",
   "metadata": {},
   "source": [
    "#### Etapa 2: Funções de Cálculo das Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37090a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_metricas_portfolio(pesos, retornos_medios_anuais, matriz_covariancia, rf_anual=0.0):\n",
    "    \"\"\"\n",
    "    Calcula retorno, volatilidade e Sharpe Ratio de um portfólio.\n",
    "\n",
    "    Parâmetros:\n",
    "        pesos: array numpy com os pesos de cada ativo\n",
    "        retornos_medios_anuais: série pandas com retornos esperados (anualizados)\n",
    "        matriz_covariancia: matriz de covariância anualizada\n",
    "        rf_anual: taxa livre de risco anual (ex.: CDI), em decimal (0.10 = 10% a.a.)\n",
    "\n",
    "    Retorna:\n",
    "        array [retorno, volatilidade, sharpe_ratio]\n",
    "    \"\"\"\n",
    "    pesos = np.array(pesos, dtype=float)\n",
    "\n",
    "    # Retorno do portfólio: Rp = Σ(Wi × Ri)\n",
    "    retorno_portfolio = float(np.sum(retornos_medios_anuais * pesos))\n",
    "\n",
    "    # Volatilidade: σp = √(W^T × Σ × W)\n",
    "    volatilidade_portfolio = float(np.sqrt(np.dot(pesos.T, np.dot(matriz_covariancia, pesos))))\n",
    "\n",
    "    # Sharpe Ratio: (Rp - rf) / σp\n",
    "    if volatilidade_portfolio > 0:\n",
    "        sharpe_ratio = (retorno_portfolio - rf_anual) / volatilidade_portfolio\n",
    "    else:\n",
    "        sharpe_ratio = np.nan\n",
    "\n",
    "    return np.array([retorno_portfolio, volatilidade_portfolio, sharpe_ratio])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03c80d8",
   "metadata": {},
   "source": [
    "#### Etapa 3: Funções Objetivo para Otimização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc0d09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimizar_volatilidade(pesos, retornos_medios_anuais, matriz_covariancia):\n",
    "    \"\"\"Função objetivo para encontrar o portfólio de Mínima Variância.\"\"\"\n",
    "    return calcular_metricas_portfolio(pesos, retornos_medios_anuais, matriz_covariancia, rf_anual=RF_ANUAL)[1]\n",
    "\n",
    "def maximizar_sharpe(pesos, retornos_medios_anuais, matriz_covariancia):\n",
    "    \"\"\"Função objetivo para encontrar o portfólio de Sharpe Máximo (excesso vs rf=CDI).\"\"\"\n",
    "    return -calcular_metricas_portfolio(pesos, retornos_medios_anuais, matriz_covariancia, rf_anual=RF_ANUAL)[2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619f5e30",
   "metadata": {},
   "source": [
    "#### Etapa 4: Configuração da Otimização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b542a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parâmetros (BUG FIX: dimensionar pelos dados realmente usados)\n",
    "ativos_otimizacao = list(retornos.columns)\n",
    "num_ativos = len(ativos_otimizacao)\n",
    "\n",
    "pesos_iniciais = np.array([1.0/num_ativos] * num_ativos)  # distribuição igual\n",
    "\n",
    "# Restrições e limites\n",
    "limites = tuple((0, 1) for _ in range(num_ativos))               # cada peso entre 0% e 100%\n",
    "restricoes = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1.0})  # soma = 1\n",
    "\n",
    "# Otimização: Carteira de Mínima Variância\n",
    "otimizacao_min_vol = minimize(\n",
    "    minimizar_volatilidade,\n",
    "    pesos_iniciais,\n",
    "    args=(retornos_medios_anuais, matriz_covariancia),\n",
    "    method='SLSQP',\n",
    "    bounds=limites,\n",
    "    constraints=restricoes\n",
    ")\n",
    "\n",
    "if not otimizacao_min_vol.success:\n",
    "    print(\"⚠️ Otimização min vol não convergiu:\", otimizacao_min_vol.message)\n",
    "\n",
    "pesos_min_vol = otimizacao_min_vol.x\n",
    "metricas_min_vol = calcular_metricas_portfolio(pesos_min_vol, retornos_medios_anuais, matriz_covariancia, rf_anual=RF_ANUAL)\n",
    "\n",
    "# Otimização: Portfólio de Sharpe Máximo (vs CDI)\n",
    "otimizacao_max_sharpe = minimize(\n",
    "    maximizar_sharpe,\n",
    "    pesos_iniciais,\n",
    "    args=(retornos_medios_anuais, matriz_covariancia),\n",
    "    method='SLSQP',\n",
    "    bounds=limites,\n",
    "    constraints=restricoes\n",
    ")\n",
    "\n",
    "if not otimizacao_max_sharpe.success:\n",
    "    print(\"⚠️ Otimização max sharpe não convergiu:\", otimizacao_max_sharpe.message)\n",
    "\n",
    "pesos_max_sharpe = otimizacao_max_sharpe.x\n",
    "metricas_max_sharpe = calcular_metricas_portfolio(pesos_max_sharpe, retornos_medios_anuais, matriz_covariancia, rf_anual=RF_ANUAL)\n",
    "\n",
    "print(\"Carteira Mín Vol (ret, vol, sharpe):\", metricas_min_vol)\n",
    "print(\"Carteira Sharpe Máx (ret, vol, sharpe):\", metricas_max_sharpe)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a751dfa0",
   "metadata": {},
   "source": [
    "#### Etapa 5: Simulação de Monte Carlo para Visualizar a Fronteira"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10402f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etapa 5: Simulação de Monte Carlo (amostragem melhor do espaço factível)\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "num_portfolios = 100000\n",
    "\n",
    "def amostrar_pesos(n_assets, n_samples, alpha_div=1.0, alpha_conc=0.25, frac_conc=0.6, frac_cantos=0.1):\n",
    "    \"\"\"\n",
    "    Gera pesos que representam melhor o espaço factível:\n",
    "    - parte mais concentrada (alpha_conc < 1)\n",
    "    - parte mais diversificada (alpha_div = 1)\n",
    "    - injeta alguns pontos próximos aos 'cantos' (quase 1 ativo)\n",
    "    \"\"\"\n",
    "    n_conc = int(n_samples * frac_conc)\n",
    "    n_div = n_samples - n_conc\n",
    "\n",
    "    w_conc = np.random.dirichlet([alpha_conc] * n_assets, size=n_conc)\n",
    "    w_div  = np.random.dirichlet([alpha_div]  * n_assets, size=n_div)\n",
    "\n",
    "    n_cantos = int(n_samples * frac_cantos)\n",
    "    if n_cantos > 0:\n",
    "        w_corner = np.zeros((n_cantos, n_assets))\n",
    "        idx = np.random.randint(0, n_assets, size=n_cantos)\n",
    "        for i in range(n_cantos):\n",
    "            main = np.random.uniform(0.75, 0.98)\n",
    "            rest = 1.0 - main\n",
    "            tmp = np.random.dirichlet([alpha_conc] * n_assets)\n",
    "            tmp[idx[i]] = 0.0\n",
    "            tmp = tmp / tmp.sum()\n",
    "            w_corner[i] = tmp * rest\n",
    "            w_corner[i, idx[i]] = main\n",
    "        W = np.vstack([w_conc, w_div, w_corner])\n",
    "    else:\n",
    "        W = np.vstack([w_conc, w_div])\n",
    "\n",
    "    return W / W.sum(axis=1, keepdims=True)\n",
    "\n",
    "W = amostrar_pesos(num_ativos, num_portfolios)\n",
    "\n",
    "# Vetorizado (muito mais rápido que loop)\n",
    "ret_arr = W @ retornos_medios_anuais.values\n",
    "vol_arr = np.sqrt(np.einsum(\"ij,jk,ik->i\", W, matriz_covariancia.values, W))\n",
    "sharpe_arr = np.where(vol_arr > 0, (ret_arr - RF_ANUAL) / vol_arr, np.nan)\n",
    "\n",
    "resultados = np.vstack([ret_arr, vol_arr, sharpe_arr])  # [retorno, risco, sharpe]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1047b726",
   "metadata": {},
   "source": [
    "#### Etapa 6: Visualização da Fronteira Eficiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fbe601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etapa 6: Visualização (Plotly) — nuvem + fronteira eficiente \"de verdade\" + destaques\n",
    "# Padrão de cores mantido: Viridis + estrela vermelha (min vol) + estrela verde (Sharpe máx)\n",
    "\n",
    "def calcular_fronteira_eficiente(retornos_medios_anuais, matriz_covariancia, limites, n_pontos=60):\n",
    "    \"\"\"Calcula a fronteira eficiente resolvendo mín. variância para retornos-alvo.\"\"\"\n",
    "    mu_vec = retornos_medios_anuais.values.astype(float)\n",
    "    cov_mat = matriz_covariancia.values.astype(float)\n",
    "\n",
    "    r_min = float(mu_vec.min())\n",
    "    r_max = float(mu_vec.max())\n",
    "    alvos = np.linspace(r_min, r_max, n_pontos)\n",
    "\n",
    "    pontos = []\n",
    "    w0 = np.array([1.0/len(mu_vec)] * len(mu_vec))\n",
    "\n",
    "    for alvo in alvos:\n",
    "        cons = (\n",
    "            {'type': 'eq', 'fun': lambda w: np.sum(w) - 1.0},\n",
    "            {'type': 'eq', 'fun': lambda w, a=alvo: float(np.dot(w, mu_vec) - a)},\n",
    "        )\n",
    "        res = minimize(lambda w: float(w @ cov_mat @ w), w0, method='SLSQP', bounds=limites, constraints=cons)\n",
    "        if res.success:\n",
    "            w = res.x\n",
    "            ret = float(np.dot(w, mu_vec))\n",
    "            vol = float(np.sqrt(w @ cov_mat @ w))\n",
    "            pontos.append((ret, vol))\n",
    "            w0 = w  # warm start\n",
    "    if not pontos:\n",
    "        return np.array([]), np.array([])\n",
    "    pts = np.array(sorted(pontos, key=lambda x: x[1]))\n",
    "    return pts[:,0], pts[:,1]\n",
    "\n",
    "front_ret, front_vol = calcular_fronteira_eficiente(retornos_medios_anuais, matriz_covariancia, limites, n_pontos=60)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Nuvem de portfólios (coloridos pelo Sharpe)\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=resultados[1, :] * 100,  # risco em %\n",
    "        y=resultados[0, :] * 100,  # retorno em %\n",
    "        mode=\"markers\",\n",
    "        name=\"Portfólios (Monte Carlo)\",\n",
    "        marker=dict(\n",
    "            color=resultados[2, :],\n",
    "            colorscale=\"Viridis\",\n",
    "            showscale=True,\n",
    "            colorbar=dict(title=\"Índice de Sharpe (vs CDI)\"),\n",
    "            size=6,\n",
    "            opacity=0.5,\n",
    "            symbol=\"circle\",\n",
    "        ),\n",
    "        hovertemplate=(\n",
    "            \"Volatilidade: %{x:.2f}%<br>\"\n",
    "            \"Retorno: %{y:.2f}%<br>\"\n",
    "            \"Sharpe: %{marker.color:.3f}\"\n",
    "            \"<extra></extra>\"\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Fronteira eficiente (linha)\n",
    "if len(front_ret) > 0:\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=front_vol * 100,\n",
    "            y=front_ret * 100,\n",
    "            mode=\"lines\",\n",
    "            name=\"Fronteira Eficiente (otimizada)\",\n",
    "            line=dict(width=3),\n",
    "            hovertemplate=\"Volatilidade: %{x:.2f}%<br>Retorno: %{y:.2f}%<extra></extra>\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Destaques\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[metricas_min_vol[1] * 100],\n",
    "        y=[metricas_min_vol[0] * 100],\n",
    "        mode=\"markers\",\n",
    "        name=\"Mínima Volatilidade\",\n",
    "        marker=dict(symbol=\"star\", size=18, color=\"red\", line=dict(color=\"black\", width=2)),\n",
    "        hovertemplate=\"<b>Mínima Volatilidade</b><br>Vol: %{x:.2f}%<br>Ret: %{y:.2f}%<extra></extra>\",\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[metricas_max_sharpe[1] * 100],\n",
    "        y=[metricas_max_sharpe[0] * 100],\n",
    "        mode=\"markers\",\n",
    "        name=\"Sharpe Máximo\",\n",
    "        marker=dict(symbol=\"star\", size=18, color=\"green\", line=dict(color=\"black\", width=2)),\n",
    "        hovertemplate=\"<b>Sharpe Máximo</b><br>Vol: %{x:.2f}%<br>Ret: %{y:.2f}%<extra></extra>\",\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=dict(text=\"Fronteira Eficiente (Markowitz) em BRL — Sharpe vs CDI\", x=0.5),\n",
    "    xaxis_title=\"Volatilidade Anualizada (Risco) — %\",\n",
    "    yaxis_title=\"Retorno Esperado Anualizado — %\",\n",
    "    template=\"plotly_white\",\n",
    "    legend=dict(x=0.01, y=0.99),\n",
    "    width=950,\n",
    "    height=650,\n",
    ")\n",
    "\n",
    "fig.update_xaxes(showgrid=True, gridwidth=1)\n",
    "fig.update_yaxes(showgrid=True, gridwidth=1)\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f62a97e",
   "metadata": {},
   "source": [
    "#### Etapa 7: Visual da matriz de covariância (Plotly Heatmap: frio/quente)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2733a926",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac5ff59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualização da Matriz de Covariância (Plotly) - cores frias/quentes conforme sinal e magnitude\n",
    "# Como o gráfico principal está em %, aqui mostramos a covariância em (%²/ano)\n",
    "cov_perc2 = matriz_covariancia.copy() * (100**2)\n",
    "\n",
    "fig_cov = go.Figure(\n",
    "    data=go.Heatmap(\n",
    "        z=cov_perc2.values,\n",
    "        x=list(cov_perc2.columns),\n",
    "        y=list(cov_perc2.index),\n",
    "        colorscale=\"RdBu\",   # azul (negativo) ↔ vermelho (positivo)\n",
    "        zmid=0,              # centraliza em 0 (essencial p/ quente/frio)\n",
    "        colorbar=dict(title=\"Covariância<br>(%²/ano)\"),\n",
    "        hovertemplate=\"Ativo X: %{x}<br>Ativo Y: %{y}<br>Cov: %{z:.4f} (%²/ano)<extra></extra>\",\n",
    "    )\n",
    ")\n",
    "\n",
    "fig_cov.update_layout(\n",
    "    title=dict(text=\"Matriz de Covariância Anualizada (%²/ano)\", x=0.5),\n",
    "    template=\"plotly_white\",\n",
    "    width=800,\n",
    "    height=680,\n",
    ")\n",
    "\n",
    "fig_cov.update_xaxes(side=\"top\")\n",
    "fig_cov.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyPort_Efic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
